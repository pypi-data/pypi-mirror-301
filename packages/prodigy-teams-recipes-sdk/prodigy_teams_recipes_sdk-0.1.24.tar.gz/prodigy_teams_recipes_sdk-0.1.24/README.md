<!-- This file is auto-generated -->

# Prodigy Teams Recipes development CLI

This package includes recipes and utilities for developing recipes for Prodigy Teams. Using the CLI, you can execute recipes locally and preview the UI forms generated for a given recipe in the app. To see all available commands or subcommands, you can use the `--help` flag, e.g. `ptr --help`.

## `ptr`

Recipes SDK for Prodigy Teams

### `ptr create-meta`

Produce a meta.json file

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `imports` | `List[str]` | Recipe packages to index |  |
| `--output` | `Union[Path, Literal['-']]` | Path for output JSON file or '-' for standard output | `'-'` |

### `ptr preview`

Preview the UI form generated by a recipe.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `name` | `str` | Name of recipe to test |  |
| `path` | `ExistingFilePath (Path)` | File containing the recipe you're developing | `None` |
| `--host` | `str` | Host to serve UI preview on | `'localhost'` |
| `--port` | `int` | Port to serve UI preview on | `9090` |

### `ptr create-object`

Add an object record, to use for 'ptr run' recipe invocations. On the cluster, you'll often want to use the named pointers to data that are stored in the Prodigy Teams server --- for instance, to provide some input data by name, rather than a cluster path. For testing, the 'ptr' commands use a json file with the objects data instead.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `name` | `str` | Name of the object |  |
| `attributes` | `str` | JSON-encoded dictionary of attributes |  |

### `ptr delete-object`

Delete an object record, to use for 'ptr run' recipe invocations. See 'create-object'.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `name` | `str` | Name of the object |  |

### `ptr list-objects`

List the local object references (datasets, inputs, models etc) to use as arguments for 'ptr run' recipe invocations. See 'create-objects'.

### `ptr clear-objects`

Remove all object records. See 'create-object'

### `ptr import-objects`

Add a set of objects from a json file. The format should be: { "cat-pictures": {...}, "org-patters": {...} } Each outer key is an arbitrary object name, and the dictionary provides its attributes. See 'create-object'

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `path` | `Path` |  |  |

### `ptr run`

#### `ptr run ner`

Named Entity Recognition: Annotate labeled text spans representing real-world objects like names, persons, countries or products.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--model.lang` | `str` | Language: Base language to use for tokenization | `<Lang.en: 'en'>` |
| `--model.highlight-chars` | `bool` | Allow highlighting individual characters instead of tokens: Keep in mind that this may produce annotations that are not aligned with the tokenization of the model you might want to train later on. | `False` |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster | `None` |
| `--model.update` | `bool` | Update the model in the loop: Update the model in the loop with the received annotations. | `False` |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate |  |
| `--patterns` | `str` | Patterns: Rules to generate pattern suggestions. Can be uploaded to your cluster. | `None` |
| `--exclude` | `List[str]` |  | `None` |
| `--segment` | `bool` | Auto-segment sentences: Uses the model if available or a simple rule-based strategy otherwise. | `False` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run spans`

Span Categorization: Annotate potentially overlapping and nested spans in the data.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--model.lang` | `str` | Language: Base language to use for tokenization | `<Lang.en: 'en'>` |
| `--model.highlight-chars` | `bool` | Allow highlighting individual characters instead of tokens: Keep in mind that this may produce annotations that are not aligned with the tokenization of the model you might want to train later on. | `False` |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster | `None` |
| `--model.update` | `bool` | Update the model in the loop: Update the model in the loop with the received annotations. | `False` |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate |  |
| `--patterns` | `str` | Patterns: Rules to generate pattern suggestions. Can be uploaded to your cluster. | `None` |
| `--exclude` | `List[str]` |  | `None` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run textcat`

Text Classification: Assign categories to whole documents or sentences.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster | `None` |
| `--model.update` | `bool` | Update the model in the loop: Update the model in the loop with the received annotations. | `False` |
| `--model.threshold` | `float` | Threshold: Score threshold to pre-select label, e.g. 0.75 to select all labels with a score of 0.75 and above | `0.5` |
| `--labels-exclusive` | `bool` | Mutually exclusive labels: Every example has exactly one correct label. | `False` |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate |  |
| `--exclude` | `List[str]` |  | `None` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run relations`

Relation Extraction: Annotate relations between tokens and spans. Also supports joint span and relation annotation.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--model.lang` | `str` | Language: Base language to use for tokenization | `<Lang.en: 'en'>` |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster | `None` |
| `--model.add-ents` | `bool` | Add named entities predicted by the model | `False` |
| `--model.add-nps` | `bool` | Add noun phrases predicted by the model | `False` |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate |  |
| `--span-label` | `List[str]` |  | `None` |
| `--patterns` | `str` | Patterns: Rules to generate pattern suggestions. Can be uploaded to your cluster. | `None` |
| `--disable-patterns` | `str` | Patterns: Rules to generate pattern suggestions. Can be uploaded to your cluster. | `None` |
| `--exclude` | `List[str]` |  | `None` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run coref`

Coreference Resolution: Annotate coreference, i.e. links of ambiguous mentions like "her" or "the woman" back to an antecedent providing more context about the entity in question

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster |  |
| `--model.add-ents` | `bool` | Add named entities predicted by the model | `False` |
| `--model.add-nps` | `bool` | Add noun phrases predicted by the model | `False` |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate | `['COREF']` |
| `--pos-tags` | `List[str]` | Part-of-speech tags: List of coarse-grained POS tags to enable for annotation | `['NOUN', 'PROPN', 'PRON', 'DET']` |
| `--poss-pron-tags` | `List[str]` | Possessive pronoun tags: List of fine-grained tag values for possessive pronoun to use in patterns | `['PRP$']` |
| `--ner-labels` | `List[str]` | Named entity labels: List of NER labels to use if model has entity recognizer | `['PERSON', 'ORG']` |
| `--exclude` | `List[str]` |  | `None` |
| `--show-arrow-heads` | `bool` | Show the arrow heads visually: If disabled, relations will be shown as lines instead of directional arrows | `False` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run dep`

Dependency Parsing: Annotate syntactic dependencies.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster |  |
| `--model.update` | `bool` | Update the model in the loop: Update the model in the loop with the received annotations. | `False` |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate |  |
| `--exclude` | `List[str]` |  | `None` |
| `--segment` | `bool` | Auto-segment sentences: Uses the model if available or a simple rule-based strategy otherwise. | `False` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run pos`

Part of Speech tagging recipe: Annotate word types.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate |  |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster |  |
| `--model.update` | `bool` | Update the model in the loop: Update the model in the loop with the received annotations. | `False` |
| `--exclude` | `List[str]` |  | `None` |
| `--segment` | `bool` | Auto-segment sentences: Uses the model if available or a simple rule-based strategy otherwise. | `False` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run terms`

Terminology List: Bootstrap a terminology list from word vectors. Terminology lists can be converted into patterns to help pre-select entity spans during annotation.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--seeds` | `List[str]` | Seed Terms: Comma-separated list of 3 or more terms |  |
| `--vectors` | `str` | Word Vectors: Loadable spaCy model with word vectors. If you have custom models, you can add them to your cluster. |  |

#### `ptr run image`

Image Annotation & Classification: Annotate bounding boxes and segments, or assign categories to images.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--label` | `List[str]` | Label(s): Comma-separated list of labels to annotate |  |
| `--segment`/`--no-segment` | `bool` | Annotate bounding boxes or segments: You'll be able to draw rectangular, polygon or freehand shapes onto the image and assign labels to them. | `True` |
| `--classify` | `bool` | Annotate image categories: Select one or more category labels that apply to the image | `False` |
| `--classify.labels-exclusive` | `bool` | Mutually exclusive labels: Every example has exactly one correct label. | `False` |
| `--exclude` | `List[str]` |  | `None` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run audio`

Annotate Audio: Annotate regions, assign categories to audio content or transcribe audio files.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--mode-regions.label` | `List[str]` | Label(s): Comma-separated list of labels to annotate | `None` |
| `--mode-classify.label` | `List[str]` | Label(s): Comma-separated list of labels to annotate | `None` |
| `--mode-classify.labels-exclusive` | `bool` | Mutually exclusive labels: Every example has exactly one correct label. | `False` |
| `--mode-transcribe.rows` | `int` | Text field rows | `3` |
| `--exclude` | `List[str]` |  | `None` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run video`

Annotate Video: Annotate regions, assign categories to video content or transcribe video files.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--mode-regions.label` | `List[str]` | Label(s): Comma-separated list of labels to annotate | `None` |
| `--mode-classify.label` | `List[str]` | Label(s): Comma-separated list of labels to annotate | `None` |
| `--mode-classify.labels-exclusive` | `bool` | Mutually exclusive labels: Every example has exactly one correct label. | `False` |
| `--mode-transcribe.rows` | `int` | Text field rows | `3` |
| `--exclude` | `List[str]` |  | `None` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run curate`

Curate and Explore: View what's in your data and accept or reject examples

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--output` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--input-asset` | `str` | Input data asset: Upload data to your cluster and it will be available here | `None` |
| `--input-input-dataset` | `str` | Existing dataset: Select an existing dataset | `None` |
| `--view-id` | `str` | ID of the interface to use |  |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run review`

Review Annotations: Review existing annotations created by multiple annotators and resolve potential conflicts by creating one final annotation.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--datasets` | `List[str]` | Review Datasets: Examples from all the datasets will be combined, and you'll review them one-by-one with conflicting examples being combined so you can pick the correct answer. |  |
| `--label` | `List[str]` |  | `None` |
| `--show-skipped` | `bool` | Include skipped answers: e.g. if annotator hit ignore or rejected manual annotation | `False` |
| `--auto-accept` | `bool` | Auto accept annotations: Automatically accept annotations with no conflicts and add them to the dataset | `False` |

#### `ptr run secrets_example`

Secrets Example: Annotate 'hello world'

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--n-examples` | `int` | Number of examples to generate | `100` |
| `--secrets` | `List[str]` |  | `None` |

#### `ptr run sent`

Sentence Segmentation: Create gold data for sentence boundaries by correcting a model's predictions

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--dataset` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `--model.name` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster |  |
| `--input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--exclude` | `List[str]` |  | `None` |
| `--goal` | `str` | Data collection goal | `'nooverlap'` |

#### `ptr run test_task`

Test Task: Task with tunable delays and errors for testing.

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--startup-delay-s` | `float` | Startup delay: Number of seconds to sleep before starting the server. | `0.0` |
| `--healthcheck-delay-s` | `float` | Healthcheck delay: Number of seconds to delay `/version`, `/health`, `/healthz` endpoints after server start (returns HTTP 503). | `0.0` |
| `--num-examples` | `int` | Number of examples | `100` |
| `--crash-on-update` | `bool` | Crash on update: Crash when annotations are saved | `False` |
| `--crash-on-startup` | `bool` | Crash on startup: If true, crashes before starting server (after startup_delay_s) | `False` |
| `--healthcheck-error` | `bool` | Healthcheck error: Returns an error from `/version`, `/health`, `/healthz` endpoints after server start (returns HTTP 500). | `False` |

#### `ptr run db_actions`

Dataset operations: Merge, copy and export annotated data

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--copy.in-dataset` | `str` | Existing dataset: Select an existing dataset | `None` |
| `--copy.in-asset` | `str` | Input data asset: Upload data to your cluster and it will be available here | `None` |
| `--copy.out-set` | `str` | New dataset: Name of the new dataset to copy to | `None` |
| `--merge.in-sets` | `List[str]` | Datasets to merge | `None` |
| `--mode-merge.out-set` | `str` | New dataset: Select an existing dataset or create a new one | `None` |

#### `ptr run hello_world`

Hello world: Print 'hello world'

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--n-lines` | `int` | Number of lines to print |  |

#### `ptr run wait_and_exit`

Wait and exit: Wait and exit with a given code

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--seconds` | `int` | Number of seconds to wait |  |
| `--exit-code` | `int` | Exit code to return: For example, 1 to exit with an error |  |

#### `ptr run print_file_length`

Print file length:

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `input-file` | `str` | Input file: Upload data to your cluster and it will be available here |  |

#### `ptr run print_dataset_or_file_length`

Print dataset or file length:

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--data-input` | `str` | Input data asset: Upload data to your cluster and it will be available here | `None` |
| `--data-input-dataset` | `str` | Existing dataset: Select an existing dataset | `None` |

#### `ptr run send_dummy_metrics`

Call PAM with dummy metrics data:

#### `ptr run create_asset`

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `asset-name` | `str` |  |  |
| `path` | `str` |  |  |

#### `ptr run train`

Train a spaCy pipeline: Train a spaCy model with one or more components on annotated data

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `--data.ner` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--ner.train` | `List[str]` | Training datasets | `None` |
| `--ner.eval` | `List[str]` |  | `None` |
| `--data.spancat` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--spancat.train` | `List[str]` | Training datasets | `None` |
| `--spancat.eval` | `List[str]` |  | `None` |
| `--data.textcat` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--textcat.train` | `List[str]` | Training datasets | `None` |
| `--textcat.eval` | `List[str]` |  | `None` |
| `--data.textcat-multilabel` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--data.textcat-multilabel.training` | `List[str]` | Training datasets | `None` |
| `--data.textcat-multilabel.evaluation` | `List[str]` |  | `None` |
| `--data.tagger` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--tagger.train` | `List[str]` | Training datasets | `None` |
| `--tagger.eval` | `List[str]` |  | `None` |
| `--data.parser` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--parser.train` | `List[str]` | Training datasets | `None` |
| `--parser.eval` | `List[str]` |  | `None` |
| `--data.senter` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--senter.train` | `List[str]` | Training datasets | `None` |
| `--senter.eval` | `List[str]` |  | `None` |
| `--data.coref` | `bool` | Training data: Annotated data for the different components to train | `False` |
| `--coref.train` | `List[str]` | Training datasets | `None` |
| `--coref.eval` | `List[str]` |  | `None` |
| `--lang` | `str` | Language: Base language to use for tokenization | `<Lang.en: 'en'>` |
| `--base-model` | `str` | Model: spaCy model. If you have custom pipelines, you can add them to your cluster | `None` |
| `--eval-split` | `float` | Portion of examples to split off for evaluation: This is applied if no dedicated evaluation datasets are provided for a component. | `0.2` |
| `--label-stats` | `bool` | Show per-label scores: Will output an additional table for each component with scores for the individual labels | `False` |
| `--verbose` | `bool` | Enable verbose logging | `False` |
| `--train-curve` | `bool` | Train Curve mode | `False` |
| `--train-curve.n-samples` | `int` | Number of samples to take: For example, 4 samples to train with 25, 50 and 100% | `1` |
| `--train-curve.show-plot` | `bool` | Show a visual plot of the curve in the logs | `False` |
| `--output` | `bool` | Register Model | `False` |
| `--output.name` | `str` | Model Name: Name to register model with in Prodigy Teams. | `None` |
| `--output.path` | `str` | Model Path: Path to upload model to. | `None` |
| `--output.version` | `str` | Model Version: Semantic version to save model as | `'0.1.0'` |
| `--output.asset-kind` | `str` | Asset Kind: Kind of asset to register model as. Defaults to 'model'. | `'model'` |
| `--config-overrides` | `List[str]` |  | `None` |

#### `ptr run llm_fetch_textcat`

Textcat LLM fetch: Gather text categorization predictions from an LLM

| Argument | Type | Description | Default |
| --- | --- | --- | --- |
| `output` | `str` | Dataset: Select an existing dataset or create a new one |  |
| `config` | `str` | spaCy config file: Remote path to a loadable spaCy config file |  |
| `input` | `str` | Input data asset: Upload data to your cluster and it will be available here |  |
| `--resume` | `bool` |  | `False` |