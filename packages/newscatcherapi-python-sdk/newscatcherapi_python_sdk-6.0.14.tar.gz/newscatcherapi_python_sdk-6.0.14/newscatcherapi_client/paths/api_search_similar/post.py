# coding: utf-8

"""
    NewsCatcher-V3 Production API

    <img src='https://uploads-ssl.webflow.com/6429857b17973b636c2195c5/646c6f1eb774ff2f2997bec5_newscatcher_.svg' width='286' height='35' /> <br>  <br>Visit our website  <a href='https://newscatcherapi.com'>https://newscatcherapi.com</a>

    The version of the OpenAPI document: 3.2.16
    Contact: maksym@newscatcherapi.com
    Generated by: https://konfigthis.com
"""

from dataclasses import dataclass
import typing_extensions
import urllib3
from pydantic import RootModel
from newscatcherapi_client.request_before_hook import request_before_hook
import json
from urllib3._collections import HTTPHeaderDict

from newscatcherapi_client.api_response import AsyncGeneratorResponse
from newscatcherapi_client import api_client, exceptions
from datetime import date, datetime  # noqa: F401
import decimal  # noqa: F401
import functools  # noqa: F401
import io  # noqa: F401
import re  # noqa: F401
import typing  # noqa: F401
import typing_extensions  # noqa: F401
import uuid  # noqa: F401

import frozendict  # noqa: F401

from newscatcherapi_client import schemas  # noqa: F401

from newscatcherapi_client.model.search_similar_post_response import SearchSimilarPostResponse as SearchSimilarPostResponseSchema
from newscatcherapi_client.model.more_like_this_request import MoreLikeThisRequest as MoreLikeThisRequestSchema
from newscatcherapi_client.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema

from newscatcherapi_client.type.more_like_this_request import MoreLikeThisRequest
from newscatcherapi_client.type.search_similar_post_response import SearchSimilarPostResponse
from newscatcherapi_client.type.http_validation_error import HTTPValidationError

from ...api_client import Dictionary
from newscatcherapi_client.pydantic.search_similar_post_response import SearchSimilarPostResponse as SearchSimilarPostResponsePydantic
from newscatcherapi_client.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
from newscatcherapi_client.pydantic.more_like_this_request import MoreLikeThisRequest as MoreLikeThisRequestPydantic

from . import path

# body param
SchemaForRequestBodyApplicationJson = MoreLikeThisRequestSchema


request_body_more_like_this_request = api_client.RequestBody(
    content={
        'application/json': api_client.MediaType(
            schema=SchemaForRequestBodyApplicationJson),
    },
    required=True,
)
_auth = [
    'apiKey',
]
SchemaFor200ResponseBodyApplicationJson = SearchSimilarPostResponseSchema


@dataclass
class ApiResponseFor200(api_client.ApiResponse):
    body: SearchSimilarPostResponse


@dataclass
class ApiResponseFor200Async(api_client.AsyncApiResponse):
    body: SearchSimilarPostResponse


_response_for_200 = api_client.OpenApiResponse(
    response_cls=ApiResponseFor200,
    response_cls_async=ApiResponseFor200Async,
    content={
        'application/json': api_client.MediaType(
            schema=SchemaFor200ResponseBodyApplicationJson),
    },
)
SchemaFor422ResponseBodyApplicationJson = HTTPValidationErrorSchema


@dataclass
class ApiResponseFor422(api_client.ApiResponse):
    body: HTTPValidationError


@dataclass
class ApiResponseFor422Async(api_client.AsyncApiResponse):
    body: HTTPValidationError


_response_for_422 = api_client.OpenApiResponse(
    response_cls=ApiResponseFor422,
    response_cls_async=ApiResponseFor422Async,
    content={
        'application/json': api_client.MediaType(
            schema=SchemaFor422ResponseBodyApplicationJson),
    },
)
_status_code_to_response = {
    '200': _response_for_200,
    '422': _response_for_422,
}
_all_accept_content_types = (
    'application/json',
)


class BaseApi(api_client.Api):

    def _post_mapped_args(
        self,
        q: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        predefined_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        from_: typing.Optional[typing.Union[str, datetime]] = None,
        to_: typing.Optional[typing.Union[str, datetime]] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[typing.Union[str, bool]] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        parent_url: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_domain_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        title_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
    ) -> api_client.MappedArgs:
        args: api_client.MappedArgs = api_client.MappedArgs()
        _body = {}
        if q is not None:
            _body["q"] = q
        if search_in is not None:
            _body["search_in"] = search_in
        if include_similar_documents is not None:
            _body["include_similar_documents"] = include_similar_documents
        if similar_documents_number is not None:
            _body["similar_documents_number"] = similar_documents_number
        if similar_documents_fields is not None:
            _body["similar_documents_fields"] = similar_documents_fields
        if predefined_sources is not None:
            _body["predefined_sources"] = predefined_sources
        if sources is not None:
            _body["sources"] = sources
        if not_sources is not None:
            _body["not_sources"] = not_sources
        if lang is not None:
            _body["lang"] = lang
        if not_lang is not None:
            _body["not_lang"] = not_lang
        if countries is not None:
            _body["countries"] = countries
        if not_countries is not None:
            _body["not_countries"] = not_countries
        if from_ is not None:
            _body["from_"] = from_
        if to_ is not None:
            _body["to_"] = to_
        if by_parse_date is not None:
            _body["by_parse_date"] = by_parse_date
        if published_date_precision is not None:
            _body["published_date_precision"] = published_date_precision
        if sort_by is not None:
            _body["sort_by"] = sort_by
        if ranked_only is not None:
            _body["ranked_only"] = ranked_only
        if from_rank is not None:
            _body["from_rank"] = from_rank
        if to_rank is not None:
            _body["to_rank"] = to_rank
        if is_headline is not None:
            _body["is_headline"] = is_headline
        if is_opinion is not None:
            _body["is_opinion"] = is_opinion
        if is_paid_content is not None:
            _body["is_paid_content"] = is_paid_content
        if parent_url is not None:
            _body["parent_url"] = parent_url
        if all_links is not None:
            _body["all_links"] = all_links
        if all_domain_links is not None:
            _body["all_domain_links"] = all_domain_links
        if word_count_min is not None:
            _body["word_count_min"] = word_count_min
        if word_count_max is not None:
            _body["word_count_max"] = word_count_max
        if page is not None:
            _body["page"] = page
        if page_size is not None:
            _body["page_size"] = page_size
        if include_nlp_data is not None:
            _body["include_nlp_data"] = include_nlp_data
        if has_nlp is not None:
            _body["has_nlp"] = has_nlp
        if theme is not None:
            _body["theme"] = theme
        if not_theme is not None:
            _body["not_theme"] = not_theme
        if title_sentiment_min is not None:
            _body["title_sentiment_min"] = title_sentiment_min
        if title_sentiment_max is not None:
            _body["title_sentiment_max"] = title_sentiment_max
        if content_sentiment_min is not None:
            _body["content_sentiment_min"] = content_sentiment_min
        if content_sentiment_max is not None:
            _body["content_sentiment_max"] = content_sentiment_max
        if iptc_tags is not None:
            _body["iptc_tags"] = iptc_tags
        if not_iptc_tags is not None:
            _body["not_iptc_tags"] = not_iptc_tags
        args.body = _body
        return args

    async def _apost_oapg(
        self,
        body: typing.Any = None,
        skip_deserialization: bool = True,
        timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
        accept_content_types: typing.Tuple[str] = _all_accept_content_types,
        content_type: str = 'application/json',
        stream: bool = False,
        **kwargs,
    ) -> typing.Union[
        ApiResponseFor200Async,
        api_client.ApiResponseWithoutDeserializationAsync,
        AsyncGeneratorResponse,
    ]:
        """
        [Post] Search For Similar Articles Request
        :param skip_deserialization: If true then api_response.response will be set but
            api_response.body and api_response.headers will not be deserialized into schema
            class instances
        """
        used_path = path.value
    
        _headers = HTTPHeaderDict()
        # TODO add cookie handling
        if accept_content_types:
            for accept_content_type in accept_content_types:
                _headers.add('Accept', accept_content_type)
        method = 'post'.upper()
        _headers.add('Content-Type', content_type)
    
        if body is schemas.unset:
            raise exceptions.ApiValueError(
                'The required body parameter has an invalid value of: unset. Set a valid value instead')
        _fields = None
        _body = None
        request_before_hook(
            resource_path=used_path,
            method=method,
            configuration=self.api_client.configuration,
            path_template='/api/search_similar',
            body=body,
            auth_settings=_auth,
            headers=_headers,
        )
        serialized_data = request_body_more_like_this_request.serialize(body, content_type)
        if 'fields' in serialized_data:
            _fields = serialized_data['fields']
        elif 'body' in serialized_data:
            _body = serialized_data['body']
    
        response = await self.api_client.async_call_api(
            resource_path=used_path,
            method=method,
            headers=_headers,
            fields=_fields,
            serialized_body=_body,
            body=body,
            auth_settings=_auth,
            timeout=timeout,
            **kwargs
        )
    
        if stream:
            if not 200 <= response.http_response.status <= 299:
                body = (await response.http_response.content.read()).decode("utf-8")
                raise exceptions.ApiStreamingException(
                    status=response.http_response.status,
                    reason=response.http_response.reason,
                    body=body,
                )
    
            async def stream_iterator():
                """
                iterates over response.http_response.content and closes connection once iteration has finished
                """
                async for line in response.http_response.content:
                    if line == b'\r\n':
                        continue
                    yield line
                response.http_response.close()
                await response.session.close()
            return AsyncGeneratorResponse(
                content=stream_iterator(),
                headers=response.http_response.headers,
                status=response.http_response.status,
                response=response.http_response
            )
    
        response_for_status = _status_code_to_response.get(str(response.http_response.status))
        if response_for_status:
            api_response = await response_for_status.deserialize_async(
                                                    response,
                                                    self.api_client.configuration,
                                                    skip_deserialization=skip_deserialization
                                                )
        else:
            # If response data is JSON then deserialize for SDK consumer convenience
            is_json = api_client.JSONDetector._content_type_is_json(response.http_response.headers.get('Content-Type', ''))
            api_response = api_client.ApiResponseWithoutDeserializationAsync(
                body=await response.http_response.json() if is_json else await response.http_response.text(),
                response=response.http_response,
                round_trip_time=response.round_trip_time,
                status=response.http_response.status,
                headers=response.http_response.headers,
            )
    
        if not 200 <= api_response.status <= 299:
            raise exceptions.ApiException(api_response=api_response)
    
        # cleanup session / response
        response.http_response.close()
        await response.session.close()
    
        return api_response


    def _post_oapg(
        self,
        body: typing.Any = None,
        skip_deserialization: bool = True,
        timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
        accept_content_types: typing.Tuple[str] = _all_accept_content_types,
        content_type: str = 'application/json',
        stream: bool = False,
    ) -> typing.Union[
        ApiResponseFor200,
        api_client.ApiResponseWithoutDeserialization,
    ]:
        """
        [Post] Search For Similar Articles Request
        :param skip_deserialization: If true then api_response.response will be set but
            api_response.body and api_response.headers will not be deserialized into schema
            class instances
        """
        used_path = path.value
    
        _headers = HTTPHeaderDict()
        # TODO add cookie handling
        if accept_content_types:
            for accept_content_type in accept_content_types:
                _headers.add('Accept', accept_content_type)
        method = 'post'.upper()
        _headers.add('Content-Type', content_type)
    
        if body is schemas.unset:
            raise exceptions.ApiValueError(
                'The required body parameter has an invalid value of: unset. Set a valid value instead')
        _fields = None
        _body = None
        request_before_hook(
            resource_path=used_path,
            method=method,
            configuration=self.api_client.configuration,
            path_template='/api/search_similar',
            body=body,
            auth_settings=_auth,
            headers=_headers,
        )
        serialized_data = request_body_more_like_this_request.serialize(body, content_type)
        if 'fields' in serialized_data:
            _fields = serialized_data['fields']
        elif 'body' in serialized_data:
            _body = serialized_data['body']
    
        response = self.api_client.call_api(
            resource_path=used_path,
            method=method,
            headers=_headers,
            fields=_fields,
            serialized_body=_body,
            body=body,
            auth_settings=_auth,
            timeout=timeout,
        )
    
        response_for_status = _status_code_to_response.get(str(response.http_response.status))
        if response_for_status:
            api_response = response_for_status.deserialize(
                                                    response,
                                                    self.api_client.configuration,
                                                    skip_deserialization=skip_deserialization
                                                )
        else:
            # If response data is JSON then deserialize for SDK consumer convenience
            is_json = api_client.JSONDetector._content_type_is_json(response.http_response.headers.get('Content-Type', ''))
            api_response = api_client.ApiResponseWithoutDeserialization(
                body=json.loads(response.http_response.data) if is_json else response.http_response.data,
                response=response.http_response,
                round_trip_time=response.round_trip_time,
                status=response.http_response.status,
                headers=response.http_response.headers,
            )
    
        if not 200 <= api_response.status <= 299:
            raise exceptions.ApiException(api_response=api_response)
    
        return api_response


class PostRaw(BaseApi):
    # this class is used by api classes that refer to endpoints with operationId fn names

    async def apost(
        self,
        q: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        predefined_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        from_: typing.Optional[typing.Union[str, datetime]] = None,
        to_: typing.Optional[typing.Union[str, datetime]] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[typing.Union[str, bool]] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        parent_url: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_domain_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        title_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        **kwargs,
    ) -> typing.Union[
        ApiResponseFor200Async,
        api_client.ApiResponseWithoutDeserializationAsync,
        AsyncGeneratorResponse,
    ]:
        args = self._post_mapped_args(
            q=q,
            search_in=search_in,
            include_similar_documents=include_similar_documents,
            similar_documents_number=similar_documents_number,
            similar_documents_fields=similar_documents_fields,
            predefined_sources=predefined_sources,
            sources=sources,
            not_sources=not_sources,
            lang=lang,
            not_lang=not_lang,
            countries=countries,
            not_countries=not_countries,
            from_=from_,
            to_=to_,
            by_parse_date=by_parse_date,
            published_date_precision=published_date_precision,
            sort_by=sort_by,
            ranked_only=ranked_only,
            from_rank=from_rank,
            to_rank=to_rank,
            is_headline=is_headline,
            is_opinion=is_opinion,
            is_paid_content=is_paid_content,
            parent_url=parent_url,
            all_links=all_links,
            all_domain_links=all_domain_links,
            word_count_min=word_count_min,
            word_count_max=word_count_max,
            page=page,
            page_size=page_size,
            include_nlp_data=include_nlp_data,
            has_nlp=has_nlp,
            theme=theme,
            not_theme=not_theme,
            title_sentiment_min=title_sentiment_min,
            title_sentiment_max=title_sentiment_max,
            content_sentiment_min=content_sentiment_min,
            content_sentiment_max=content_sentiment_max,
            iptc_tags=iptc_tags,
            not_iptc_tags=not_iptc_tags,
        )
        return await self._apost_oapg(
            body=args.body,
            **kwargs,
        )
    
    def post(
        self,
        q: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        predefined_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        from_: typing.Optional[typing.Union[str, datetime]] = None,
        to_: typing.Optional[typing.Union[str, datetime]] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[typing.Union[str, bool]] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        parent_url: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_domain_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        title_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
    ) -> typing.Union[
        ApiResponseFor200,
        api_client.ApiResponseWithoutDeserialization,
    ]:
        """ This endpoint returns a list of articles that are similar to the query provided. You also have the option to get similar articles for the results of a search. """
        args = self._post_mapped_args(
            q=q,
            search_in=search_in,
            include_similar_documents=include_similar_documents,
            similar_documents_number=similar_documents_number,
            similar_documents_fields=similar_documents_fields,
            predefined_sources=predefined_sources,
            sources=sources,
            not_sources=not_sources,
            lang=lang,
            not_lang=not_lang,
            countries=countries,
            not_countries=not_countries,
            from_=from_,
            to_=to_,
            by_parse_date=by_parse_date,
            published_date_precision=published_date_precision,
            sort_by=sort_by,
            ranked_only=ranked_only,
            from_rank=from_rank,
            to_rank=to_rank,
            is_headline=is_headline,
            is_opinion=is_opinion,
            is_paid_content=is_paid_content,
            parent_url=parent_url,
            all_links=all_links,
            all_domain_links=all_domain_links,
            word_count_min=word_count_min,
            word_count_max=word_count_max,
            page=page,
            page_size=page_size,
            include_nlp_data=include_nlp_data,
            has_nlp=has_nlp,
            theme=theme,
            not_theme=not_theme,
            title_sentiment_min=title_sentiment_min,
            title_sentiment_max=title_sentiment_max,
            content_sentiment_min=content_sentiment_min,
            content_sentiment_max=content_sentiment_max,
            iptc_tags=iptc_tags,
            not_iptc_tags=not_iptc_tags,
        )
        return self._post_oapg(
            body=args.body,
        )

class Post(BaseApi):

    async def apost(
        self,
        q: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        predefined_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        from_: typing.Optional[typing.Union[str, datetime]] = None,
        to_: typing.Optional[typing.Union[str, datetime]] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[typing.Union[str, bool]] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        parent_url: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_domain_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        title_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        validate: bool = False,
        **kwargs,
    ) -> SearchSimilarPostResponsePydantic:
        raw_response = await self.raw.apost(
            q=q,
            search_in=search_in,
            include_similar_documents=include_similar_documents,
            similar_documents_number=similar_documents_number,
            similar_documents_fields=similar_documents_fields,
            predefined_sources=predefined_sources,
            sources=sources,
            not_sources=not_sources,
            lang=lang,
            not_lang=not_lang,
            countries=countries,
            not_countries=not_countries,
            from_=from_,
            to_=to_,
            by_parse_date=by_parse_date,
            published_date_precision=published_date_precision,
            sort_by=sort_by,
            ranked_only=ranked_only,
            from_rank=from_rank,
            to_rank=to_rank,
            is_headline=is_headline,
            is_opinion=is_opinion,
            is_paid_content=is_paid_content,
            parent_url=parent_url,
            all_links=all_links,
            all_domain_links=all_domain_links,
            word_count_min=word_count_min,
            word_count_max=word_count_max,
            page=page,
            page_size=page_size,
            include_nlp_data=include_nlp_data,
            has_nlp=has_nlp,
            theme=theme,
            not_theme=not_theme,
            title_sentiment_min=title_sentiment_min,
            title_sentiment_max=title_sentiment_max,
            content_sentiment_min=content_sentiment_min,
            content_sentiment_max=content_sentiment_max,
            iptc_tags=iptc_tags,
            not_iptc_tags=not_iptc_tags,
            **kwargs,
        )
        if validate:
            return RootModel[SearchSimilarPostResponsePydantic](raw_response.body).root
        return api_client.construct_model_instance(SearchSimilarPostResponsePydantic, raw_response.body)
    
    
    def post(
        self,
        q: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        predefined_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        from_: typing.Optional[typing.Union[str, datetime]] = None,
        to_: typing.Optional[typing.Union[str, datetime]] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[typing.Union[str, bool]] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        parent_url: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_domain_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        title_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        validate: bool = False,
    ) -> SearchSimilarPostResponsePydantic:
        raw_response = self.raw.post(
            q=q,
            search_in=search_in,
            include_similar_documents=include_similar_documents,
            similar_documents_number=similar_documents_number,
            similar_documents_fields=similar_documents_fields,
            predefined_sources=predefined_sources,
            sources=sources,
            not_sources=not_sources,
            lang=lang,
            not_lang=not_lang,
            countries=countries,
            not_countries=not_countries,
            from_=from_,
            to_=to_,
            by_parse_date=by_parse_date,
            published_date_precision=published_date_precision,
            sort_by=sort_by,
            ranked_only=ranked_only,
            from_rank=from_rank,
            to_rank=to_rank,
            is_headline=is_headline,
            is_opinion=is_opinion,
            is_paid_content=is_paid_content,
            parent_url=parent_url,
            all_links=all_links,
            all_domain_links=all_domain_links,
            word_count_min=word_count_min,
            word_count_max=word_count_max,
            page=page,
            page_size=page_size,
            include_nlp_data=include_nlp_data,
            has_nlp=has_nlp,
            theme=theme,
            not_theme=not_theme,
            title_sentiment_min=title_sentiment_min,
            title_sentiment_max=title_sentiment_max,
            content_sentiment_min=content_sentiment_min,
            content_sentiment_max=content_sentiment_max,
            iptc_tags=iptc_tags,
            not_iptc_tags=not_iptc_tags,
        )
        if validate:
            return RootModel[SearchSimilarPostResponsePydantic](raw_response.body).root
        return api_client.construct_model_instance(SearchSimilarPostResponsePydantic, raw_response.body)


class ApiForpost(BaseApi):
    # this class is used by api classes that refer to endpoints by path and http method names

    async def apost(
        self,
        q: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        predefined_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        from_: typing.Optional[typing.Union[str, datetime]] = None,
        to_: typing.Optional[typing.Union[str, datetime]] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[typing.Union[str, bool]] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        parent_url: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_domain_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        title_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        **kwargs,
    ) -> typing.Union[
        ApiResponseFor200Async,
        api_client.ApiResponseWithoutDeserializationAsync,
        AsyncGeneratorResponse,
    ]:
        args = self._post_mapped_args(
            q=q,
            search_in=search_in,
            include_similar_documents=include_similar_documents,
            similar_documents_number=similar_documents_number,
            similar_documents_fields=similar_documents_fields,
            predefined_sources=predefined_sources,
            sources=sources,
            not_sources=not_sources,
            lang=lang,
            not_lang=not_lang,
            countries=countries,
            not_countries=not_countries,
            from_=from_,
            to_=to_,
            by_parse_date=by_parse_date,
            published_date_precision=published_date_precision,
            sort_by=sort_by,
            ranked_only=ranked_only,
            from_rank=from_rank,
            to_rank=to_rank,
            is_headline=is_headline,
            is_opinion=is_opinion,
            is_paid_content=is_paid_content,
            parent_url=parent_url,
            all_links=all_links,
            all_domain_links=all_domain_links,
            word_count_min=word_count_min,
            word_count_max=word_count_max,
            page=page,
            page_size=page_size,
            include_nlp_data=include_nlp_data,
            has_nlp=has_nlp,
            theme=theme,
            not_theme=not_theme,
            title_sentiment_min=title_sentiment_min,
            title_sentiment_max=title_sentiment_max,
            content_sentiment_min=content_sentiment_min,
            content_sentiment_max=content_sentiment_max,
            iptc_tags=iptc_tags,
            not_iptc_tags=not_iptc_tags,
        )
        return await self._apost_oapg(
            body=args.body,
            **kwargs,
        )
    
    def post(
        self,
        q: str,
        search_in: typing.Optional[str] = None,
        include_similar_documents: typing.Optional[bool] = None,
        similar_documents_number: typing.Optional[int] = None,
        similar_documents_fields: typing.Optional[str] = None,
        predefined_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_sources: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_lang: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_countries: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        from_: typing.Optional[typing.Union[str, datetime]] = None,
        to_: typing.Optional[typing.Union[str, datetime]] = None,
        by_parse_date: typing.Optional[bool] = None,
        published_date_precision: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        ranked_only: typing.Optional[typing.Union[str, bool]] = None,
        from_rank: typing.Optional[int] = None,
        to_rank: typing.Optional[int] = None,
        is_headline: typing.Optional[bool] = None,
        is_opinion: typing.Optional[bool] = None,
        is_paid_content: typing.Optional[bool] = None,
        parent_url: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        all_domain_links: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        word_count_min: typing.Optional[int] = None,
        word_count_max: typing.Optional[int] = None,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        include_nlp_data: typing.Optional[bool] = None,
        has_nlp: typing.Optional[bool] = None,
        theme: typing.Optional[str] = None,
        not_theme: typing.Optional[str] = None,
        title_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        title_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_min: typing.Optional[typing.Union[int, float]] = None,
        content_sentiment_max: typing.Optional[typing.Union[int, float]] = None,
        iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
        not_iptc_tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
    ) -> typing.Union[
        ApiResponseFor200,
        api_client.ApiResponseWithoutDeserialization,
    ]:
        """ This endpoint returns a list of articles that are similar to the query provided. You also have the option to get similar articles for the results of a search. """
        args = self._post_mapped_args(
            q=q,
            search_in=search_in,
            include_similar_documents=include_similar_documents,
            similar_documents_number=similar_documents_number,
            similar_documents_fields=similar_documents_fields,
            predefined_sources=predefined_sources,
            sources=sources,
            not_sources=not_sources,
            lang=lang,
            not_lang=not_lang,
            countries=countries,
            not_countries=not_countries,
            from_=from_,
            to_=to_,
            by_parse_date=by_parse_date,
            published_date_precision=published_date_precision,
            sort_by=sort_by,
            ranked_only=ranked_only,
            from_rank=from_rank,
            to_rank=to_rank,
            is_headline=is_headline,
            is_opinion=is_opinion,
            is_paid_content=is_paid_content,
            parent_url=parent_url,
            all_links=all_links,
            all_domain_links=all_domain_links,
            word_count_min=word_count_min,
            word_count_max=word_count_max,
            page=page,
            page_size=page_size,
            include_nlp_data=include_nlp_data,
            has_nlp=has_nlp,
            theme=theme,
            not_theme=not_theme,
            title_sentiment_min=title_sentiment_min,
            title_sentiment_max=title_sentiment_max,
            content_sentiment_min=content_sentiment_min,
            content_sentiment_max=content_sentiment_max,
            iptc_tags=iptc_tags,
            not_iptc_tags=not_iptc_tags,
        )
        return self._post_oapg(
            body=args.body,
        )

