{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from deepchopper import  remove_intervals_and_keep_left, smooth_label_region, summary_predict, get_label_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchopper.utils import alignment_predict, highlight_target, highlight_targets\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "\n",
    "- [ ] summary chop  or not chop\n",
    "- [ ] summary chop internal or terminal\n",
    "- [ ] chop only has one interval\n",
    "- [ ] summary chop interval size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_data_folder  = \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_16-17-16/predicts/0/0.pt\"\n",
    "# hyena_data_folder = \"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_20-30-28/predicts/0/0.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def id2seq(ids: list[int]):\n",
    "#     # A', 'C', 'G', 'T', 'N'\n",
    "#     table = {7: \"A\", 8: \"C\", 9: \"G\", 10: \"T\", 11: \"N\"}\n",
    "#     return \"\".join(table[c] for c in ids)\n",
    "\n",
    "\n",
    "# def majority_voting(labels, window_size):\n",
    "#     # Ensure window size is odd to have a central token\n",
    "#     if window_size % 2 == 0:\n",
    "#         window_size += 1\n",
    "\n",
    "#     half_window = window_size // 2\n",
    "#     smoothed_labels = []\n",
    "\n",
    "#     for i in range(len(labels)):\n",
    "#         # Extract the context window\n",
    "#         start = max(0, i - half_window)\n",
    "#         end = min(len(labels), i + half_window + 1)\n",
    "#         window = labels[start:end]\n",
    "\n",
    "#         # # 11100 will be 11111\n",
    "#         if end == len(labels):\n",
    "#             window += [1] * (i + half_window + 1 - end)\n",
    "\n",
    "#         # Choose the most common label in the window\n",
    "#         most_common = max(set(window), key=window.count)\n",
    "#         smoothed_labels.append(most_common)\n",
    "\n",
    "#     return smoothed_labels\n",
    "\n",
    "\n",
    "# def ascii_values_to_string(ascii_values):\n",
    "#     return \"\".join(chr(value) for value in ascii_values)\n",
    "\n",
    "\n",
    "# def convert_id_str(ids):\n",
    "#     return (ascii_values_to_string(i[2 : i[0] + 2]) for i in ids)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FqRecord:\n",
    "    id: str\n",
    "    seq: str\n",
    "    qual: str\n",
    "\n",
    "    def to_str(self):\n",
    "        return f\"{self.id}\\n{self.seq}\\n+\\n{self.qual}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Predict:\n",
    "    prediction: list[int]\n",
    "    seq: str\n",
    "    id: str\n",
    "    is_trucation: bool\n",
    "    qual: str | None = None\n",
    "\n",
    "    def is_terminal(self, *, threshold=10, smooth=False, window_size=None) -> bool:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def is_polya(self) -> bool:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def prediction_region(self):\n",
    "        return get_label_region(self.prediction)\n",
    "\n",
    "    def smooth_prediction_region(self, window_size):\n",
    "        return get_label_region(self.smooth_label(window_size))\n",
    "\n",
    "    def smooth_label(self, window_size):\n",
    "        return majority_voting(self.prediction, window_size)\n",
    "\n",
    "    @property\n",
    "    def seq_len(self):\n",
    "        return len(self.true_seq)\n",
    "\n",
    "    def fetch_qual(self, fq_records):\n",
    "        self.qual = fq_records[self.id].qual\n",
    "\n",
    "    @property\n",
    "    def qual_array(self):\n",
    "        if self.qual is None:\n",
    "            raise ValueError(\"no qual, please fetch qual first\")\n",
    "        return [ord(c) - 33 for c in list(self.qual)]\n",
    "\n",
    "    def vis_qual_static(self, start: int | None = None, end: int | None = None, figure_size=(20, 1)):\n",
    "        if self.qual is None:\n",
    "            raise ValueError(\"no qual, please fetch qual first\")\n",
    "\n",
    "        start = 0 if start is None else start\n",
    "        end = len(self.seq) if end is None else end\n",
    "\n",
    "        qual = np.array([ord(c) - 33 for c in list(self.qual[start:end])]).reshape(1, -1)\n",
    "        seq = list(self.seq[start:end])\n",
    "\n",
    "        # Creating the heatmap\n",
    "        fig, ax = plt.subplots(figsize=figure_size)  # Set a wide figure to accommodate the sequence\n",
    "        cax = ax.imshow(qual, aspect=\"auto\", cmap=\"viridis\")\n",
    "        cbar = plt.colorbar(cax, ax=ax, orientation=\"vertical\")\n",
    "        cbar.set_label(\"Value\")\n",
    "        # Setting up the sequence as x-axis labels\n",
    "        ax.set_xticks(np.arange(len(seq)))\n",
    "        ax.set_xticklabels(seq, rotation=90)  # Rotate labels for better readability\n",
    "        # Remove y-axis labels as there's only one row\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f\"{self.id}: {start}-{end}\")\n",
    "        plt.close()\n",
    "\n",
    "    def print_seq(self, *, smooth=False, smooth_window_size: int | None = None):\n",
    "        regions = self.chop_intervals(smooth=smooth, smooth_window_size=smooth_window_size)\n",
    "\n",
    "        print(f\"id     : {self.id}\")\n",
    "        print(f\"regions: {regions}\")\n",
    "        highlight_targets(self.seq, regions)\n",
    "\n",
    "    def compare_smooth(self, smooth_window_size: int):\n",
    "        regions = self.prediction_region\n",
    "\n",
    "        window_size = smooth_window_size\n",
    "        smooth_regions = self.smooth_prediction_region(window_size)\n",
    "\n",
    "        print(f\"id      : {self.id}\")\n",
    "        print(f\"original: {regions}\")\n",
    "        print(f\"smooth  : {smooth_regions}\")\n",
    "        highlight_targets(self.seq, regions)\n",
    "        highlight_targets(self.seq, smooth_regions)\n",
    "\n",
    "    def chop_intervals(self, *, smooth: bool, smooth_window_size: int | None) -> list[tuple[int, int]]:\n",
    "        if smooth:\n",
    "            if smooth_window_size is None:\n",
    "                raise ValueError(\"please provide window size\")\n",
    "            window_size = smooth_window_size\n",
    "            regions = self.smooth_prediction_region(window_size)\n",
    "        else:\n",
    "            regions = self.prediction_region\n",
    "        return regions\n",
    "\n",
    "    def to_fqs_record(self, intervals: list[tuple[int, int]]):\n",
    "        if self.qual is None:\n",
    "            raise ValueError(\"no qual, please fetch qual first\")\n",
    "\n",
    "        assert len(self.qual) == len(self.seq)\n",
    "\n",
    "        seqs, saved_intervals = remove_intervals_and_keep_left(self.seq, intervals)\n",
    "        quals, saved_intervals = remove_intervals_and_keep_left(self.qual, intervals)\n",
    "\n",
    "        assert len(seqs) == len(quals)\n",
    "        for ind, (seq, qual) in enumerate(zip(seqs, quals, strict=True)):\n",
    "            record_id = f\"@{self.id}|{saved_intervals[ind][0], saved_intervals[ind][1]}\"\n",
    "            yield FqRecord(id=record_id, seq=seq, qual=qual)\n",
    "\n",
    "    def smooth_and_select_intervals(\n",
    "        self,\n",
    "        smooth_window_size: int,\n",
    "        min_interval_length: int,\n",
    "        approved_interval_nums: int = 1,\n",
    "    ) -> list[tuple[int, int]]:\n",
    "        chop_intervals = self.chop_intervals(smooth=True, smooth_window_size=smooth_window_size)\n",
    "\n",
    "        results = []\n",
    "        for interval in chop_intervals:\n",
    "            if interval[1] - interval[0] > min_interval_length:\n",
    "                results.append(interval)\n",
    "\n",
    "        if len(results) > approved_interval_nums:\n",
    "            return []\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "class BatchPredict:\n",
    "    def __init__(self, batch_prediction, smooth_window_size=9):\n",
    "        self.smooth_window_size = smooth_window_size\n",
    "        self.data_path = batch_prediction\n",
    "\n",
    "        self.data = torch.load(batch_prediction)\n",
    "        self.batch_size = self.data[\"seq\"].shape[0]\n",
    "        self.batch_predicts = []\n",
    "\n",
    "        predictions, _labels = summary_predict(\n",
    "            self.data[\"prediction\"].argmax(-1).numpy(), self.data[\"target\"].numpy(), -100\n",
    "        )\n",
    "        seqs, _labels = summary_predict(self.data[\"seq\"].numpy(), self.data[\"target\"].numpy(), -100)\n",
    "\n",
    "        for idx in range(len(predictions)):\n",
    "            self.batch_predicts.append(\n",
    "                Predict(\n",
    "                    prediction=predictions[idx],\n",
    "                   seq=id2seq(seqs[idx]),\n",
    "                    id=ascii_values_to_string(self.data[\"id\"][idx][2 : self.data[\"id\"][idx][0] + 2]),\n",
    "                    is_trucation=bool(self.data[\"id\"][idx][1]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{__class__.__name__}(batch_size={self.batch_size}, data={self.data_path})\"\n",
    "\n",
    "    def print_all_seq(self, *, smooth=False, smooth_window_size: int | None = None):\n",
    "        for predict in self.batch_predicts:\n",
    "            if smooth:\n",
    "                window_size = smooth_window_size if smooth_window_size is not None else self.smooth_window_size\n",
    "                regions = predict.smooth_prediction_region(window_size)\n",
    "            else:\n",
    "                regions = predict.prediction_region\n",
    "\n",
    "            print(f\"id     : {predict.id}\")\n",
    "            print(f\"regions: {regions}\")\n",
    "            highlight_targets(predict.seq, regions)\n",
    "\n",
    "    def compare_smooth(self, smooth_window_size: int | None = None):\n",
    "        for predict in self.batch_predicts:\n",
    "            regions = predict.prediction_region\n",
    "\n",
    "            window_size = smooth_window_size if smooth_window_size is not None else self.smooth_window_size\n",
    "            smooth_regions = predict.smooth_prediction_region(window_size)\n",
    "\n",
    "            print(f\"id      : {predict.id}\")\n",
    "            print(f\"original: {regions}\")\n",
    "            print(f\"smooth  : {smooth_regions}\")\n",
    "            highlight_targets(predict.seq, regions)\n",
    "            highlight_targets(predict.seq, smooth_regions)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.batch_predicts[idx]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.batch_predicts)\n",
    "\n",
    "    def __next__(self):\n",
    "        return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_all_predicts(chunk_result_path:list[Path], smooth_window_size = int):\n",
    "    for chunk_path in chunk_result_path:\n",
    "        print(f\"load chunk data from {chunk_path}\")\n",
    "        for batch in (chunk_path).glob(\"*.pt\"):\n",
    "            try:\n",
    "                result = BatchPredict(batch, smooth_window_size=smooth_window_size)\n",
    "            except Exception as  e:\n",
    "                print(f\"fail to load batch {batch}: {e}\")\n",
    "            else:\n",
    "                yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from needletail import parse_fastx_file, NeedletailError, reverse_complement, normalize_seq\n",
    "\n",
    "def collect_fq_records(file: Path):\n",
    "    result = {}\n",
    "    try:\n",
    "        for record in parse_fastx_file(file.as_posix()):\n",
    "            result[record.id]  = record\n",
    "    except NeedletailError:\n",
    "        print(\"Invalid Fastq file\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "def collect_sam_records(file: Path):\n",
    "    if not isinstance(file, Path):\n",
    "        file = Path(file)\n",
    "    \n",
    "    result = {}\n",
    "    samfile = pysam.AlignmentFile(file.as_posix(), \"rb\")\n",
    "\n",
    "    for read in samfile.fetch():\n",
    "        result[read.query_name]  = read \n",
    "\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_records = collect_sam_records(\"/projects/b1171/ylk4626/project/DeepChopper/data/eval/real_data/dorado_without_trim_fqs/VCaP.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chunks = [Path(\"/projects/b1171/ylk4626/project/DeepChopper/tests/data/eval/chunk0\"),\n",
    "               Path(\"/projects/b1171/ylk4626/project/DeepChopper/tests/data/eval/chunk1\")]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_records = collect_fq_records(Path(\"/projects/b1171/ylk4626/project/DeepChopper/data/eval/real_data/dorado_without_trim_fqs/VCaP.fastq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fq_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn check point /projects/b1171/ylk4626/project/DeepChopper/logs/train/runs/2024-04-07_12-01-37/checkpoints/epoch_036_f1_0.9914.ckpt \n",
    "# heyna check point  /projects/b1171/ylk4626/project/DeepChopper/logs/train/runs/2024-04-09_20-13-03/checkpoints/epoch_007_f1_0.9931.ckpt\n",
    "\n",
    "\n",
    "## K562\n",
    "\n",
    "# data/eval/real_data/dorado_without_trim_fqs/K562.fastq_chunks/K562.fastq_0.parquet\n",
    "\n",
    "# hyena result: chunk 0 1 2 3 4 5 6\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_20-50-48\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_20-30-28\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-01-16\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-17-21\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-28-45\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-39-48\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-51-10\n",
    "\n",
    "\n",
    "# hyena_results = [\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_20-50-48/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_20-30-28/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-01-16/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-17-21/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-28-45/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-39-48/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-12_22-51-10/predicts/0\"),\n",
    "# ]\n",
    "# # cnn result\n",
    "\n",
    "# cnn_results = [\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-14_11-54-02/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-14_11-59-59/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-14_12-07-39/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-14_12-15-06/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-14_12-20-36/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-14_12-26-11/predicts/0\"),\n",
    "#     Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-14_12-31-16/predicts/0\"),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VCaP\n",
    "\n",
    "# hyena \n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_15-59-13\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_16-32-10\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_22-42-00\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_23-23-31\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-16_00-26-11\n",
    "#\n",
    "\n",
    "hyena_results = [\n",
    "Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_15-59-13/predicts/0\"),\n",
    "Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_16-32-10/predicts/0\"),\n",
    "Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_22-42-00/predicts/0\"),\n",
    "Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-15_23-23-31/predicts/0\"),\n",
    "Path('/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-16_00-26-11/predicts/0'),\n",
    "Path(\"/projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-16_10-38-12/predicts/0\"),\n",
    "\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-16_11-18-42\n",
    "# /projects/b1171/ylk4626/project/DeepChopper/logs/eval/runs/2024-04-16_12-10-35\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = 20000\n",
    "all_predicts = []\n",
    "idx = 0\n",
    "for p in gather_all_predicts(hyena_results[:1], smooth_window_size=11):\n",
    "    idx+=1\n",
    "    if idx <= data_points:\n",
    "        all_predicts.append(p)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in all_predicts:\n",
    "    p.fetch_qual(fq_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicts_with_chop  = []\n",
    "all_predicts_smooth_with_chop = []\n",
    "smooth_intervals = {}\n",
    "\n",
    "for p in all_predicts:\n",
    "    if len(p.prediction_region) > 0:\n",
    "        all_predicts_with_chop.append(p)\n",
    "        \n",
    "    smooth_regions = p.smooth_and_select_intervals(smooth_window_size=11, min_interval_length=5, approved_interval_nums=999)\n",
    "\n",
    "    if len(smooth_regions) > 0:\n",
    "        all_predicts_smooth_with_chop.append(p)\n",
    "\n",
    "    smooth_intervals[p.id] = smooth_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predicts_with_chop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predicts_smooth_with_chop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_chop_predicts = [] \n",
    "\n",
    "for p in all_predicts_smooth_with_chop:        \n",
    "    reg = smooth_intervals[p.id]\n",
    "    for r in reg:\n",
    "        if r[1] / len(p.seq) < 0.7:\n",
    "            internal_chop_predicts.append(p)\n",
    "            highlight_targets(p.seq, reg)\n",
    "            break\n",
    "    # p.compare_smooth(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(internal_chop_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx  = 0 \n",
    "for p in all_predicts_smooth_with_chop:\n",
    "    idx +=1\n",
    "    if idx > 100:\n",
    "        break\n",
    "    reg = smooth_intervals[p.id]\n",
    "        \n",
    "    oreg = p.prediction_region \n",
    "\n",
    "    print(f\"orignal:{oreg}\")\n",
    "    print(f\"smooth: {reg}\")\n",
    "\n",
    "    highlight_targets(p.seq, oreg)\n",
    "    highlight_targets(p.seq, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicts[0].vis_qual_static(all_predicts[0].smooth_prediction_region(11)[0][0] - 10 , all_predicts[0].smooth_prediction_region(11)[0][1] + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def get_data_hist_for_num_of_intervals(all_predicts, * ,smooth:bool = False,\n",
    "    smooth_window_size:int|None= None, \n",
    "    min_interval_length: int| None= None, \n",
    "    approved_interval_nums: int|None = None):\n",
    "\n",
    "    number = [ ]\n",
    "    for predict in all_predicts:\n",
    "        if smooth:\n",
    "            number.append(len(predict.smooth_and_select_intervals(smooth_window_size=smooth_window_size, \n",
    "                                            min_interval_length=min_interval_length, \n",
    "                                            approved_interval_nums=approved_interval_nums)))\n",
    "        else:\n",
    "            number.append(len(predict.prediction_region))\n",
    "\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data =  [] \n",
    "smooth_plot_data = []\n",
    "for p in all_predicts_with_chop:\n",
    "    plot_data.append(len(p.prediction_region))\n",
    "    smooth_plot_data.append(len(smooth_intervals[p.id]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data  = get_data_hist_for_num_of_intervals(cnn_all_predicts)\n",
    "# smooth_data= get_data_hist_for_num_of_intervals(cnn_all_predicts, smooth=True, smooth_window_size=9, min_interval_length=1, approved_interval_nums=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_hist_for_num_of_intervals(data, figsize=(10,6), title=None):\n",
    "    # Create histogram with a kernel density estimate\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.histplot(data, kde=True, color='green', line_kws={'linewidth': 2}, discrete=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hist_for_num_of_intervals(plot_data, title=\"Original Intervals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hist_for_num_of_intervals(smooth_plot_data, title=\"Smooth Intervals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hist_for_num_of_intervals(np.array(plot_data) - np.array(smooth_plot_data), title=\"Diff with/withou Smooth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "ploas = 0\n",
    "only_one = 0\n",
    "for p in all_predicts_with_chop:\n",
    "    smooth_region = smooth_intervals[p.id]\n",
    "    \n",
    "    if len(smooth_region) == 1:\n",
    "        only_one +=1 \n",
    "        ploa_counter = Counter(p.seq[smooth_region[0][0] -10: smooth_region[0][0]])\n",
    "        if ploa_counter.get(\"A\", 0 ) >= 3:\n",
    "            ploas +=1\n",
    "        else:\n",
    "            print(p.id)\n",
    "            highlight_targets(p.seq, smooth_region)\n",
    "        if smooth_region[0][1] / len(p.seq) < 0.7:\n",
    "            idx +=1\n",
    "            # print(p.id)\n",
    "            # highlight_targets(p.true_seq, smooth_region)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ploas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_size_data = []\n",
    "for p in all_predicts_with_chop:\n",
    "    smooth_region = smooth_intervals[p.id]\n",
    "    \n",
    "    if len(smooth_region) == 1:\n",
    "        size = smooth_region[0][1] - smooth_region[0][0]\n",
    "        plot_region_size_data.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hist_for_num_of_intervals(plot_region_size_data, title=\"Chop Size of clean data (smooth)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_size_data = []\n",
    "for p in all_predicts_with_chop:\n",
    "    smooth_region = smooth_intervals[p.id]\n",
    "    \n",
    "    if len(smooth_region) == 1:\n",
    "        size = smooth_region[0][1] - smooth_region[0][0]\n",
    "        plot_region_size_data.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_one_smooth_preditions = []\n",
    "\n",
    "for p in all_predicts_with_chop:\n",
    "    smooth_region = smooth_intervals[p.id]\n",
    "    \n",
    "    if len(smooth_region) > 1:\n",
    "        more_than_one_smooth_preditions.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(more_than_one_smooth_preditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from textwrap import wrap \n",
    "\n",
    "from collections import defaultdict \n",
    "\n",
    "def verify_result_with_sam_records(predicts, smooth_intervals, sam_records, interval_threshold: float =0.7, overlap_threshold: int= 20):\n",
    "    pat_left_s = re.compile(r\"^(\\d+)S\")\n",
    "    pat_right_s = re.compile(r\"(\\d+)S$\")\n",
    "\n",
    "    \n",
    "    predict_read = sam_records.get(predict.id, None)\n",
    "    if predict_read is None:\n",
    "        print(f\"the read is not map\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    left_mat = pat_left_s.search(predict_read.cigarstring)\n",
    "    right_mat = pat_right_s.search(predict_read.cigarstring)\n",
    "\n",
    "    ls_len = int(left_mat.group(1)) if left_mat else 0\n",
    "    rs_len = int(right_mat.group(1)) if right_mat else 0\n",
    "\n",
    "    intervals = smooth_intervals[predict.id]\n",
    "\n",
    "    # define results \n",
    "    overlap_results = defaultdict(int)\n",
    "\n",
    "    for interval in intervals:\n",
    "        quals = predict.qual_array[interval[0]:interval[1]]\n",
    "        average_qual  = sum(quals)/len(quals)\n",
    "\n",
    "        if interval[1] / interval_threshold <= interval_threshold:\n",
    "            # internal\n",
    "            \n",
    "            if ls_len != 0:\n",
    "                # if has ls\n",
    "                if abs(interval[1]-ls_len) < overlap_threshold:\n",
    "                    overlap_results[\"internal\"] +=1 \n",
    "\n",
    "            if rs_len !=-\n",
    "                    \n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wrap_str(ostr, width):\n",
    "    return \"\\n\".join(wrap(ostr,width))\n",
    "    \n",
    "def show_sam_record(predict, smooth_intervals, sam_records):\n",
    "    pat_left_s = re.compile(r\"^(\\d+)S\")\n",
    "    pat_right_s = re.compile(r\"(\\d+)S$\")\n",
    "\n",
    "    seq_len = len(predict.seq)\n",
    "    txt_width = 120\n",
    "    \n",
    "    print(f\"\\nread id {predict.id} seq len: {seq_len}\")\n",
    "\n",
    "    for interval in smooth_intervals[predict.id]:\n",
    "        quals = predict.qual_array[interval[0]:interval[1]]\n",
    "        average_qual  = sum(quals)/len(quals)\n",
    "        print(f\"smooth interval : {interval} len: {interval[1] - interval[0]}     {average_qual=}\")\n",
    "\n",
    "    highlight_targets(predict.seq, smooth_intervals[predict.id])    \n",
    "    \n",
    "    predict_read = sam_records.get(predict.id, None)\n",
    "    if predict_read is None:\n",
    "        print(f\"the read is not map\")\n",
    "        return\n",
    "\n",
    "    print(f\"{predict_read.reference_id=} {predict_read.mapping_quality=}\")\n",
    "    print(f\"{predict_read.reference_start=} {predict_read.reference_end=}\")\n",
    "\n",
    "\n",
    "    print(f\"cigar: {wrap_str(predict_read.cigarstring, txt_width)}\")\n",
    "\n",
    "    \n",
    "    left_mat = pat_left_s.search(predict_read.cigarstring)\n",
    "    right_mat = pat_right_s.search(predict_read.cigarstring)\n",
    "\n",
    "    ls_len = int(left_mat.group(1)) if left_mat else None\n",
    "    rs_len = int(right_mat.group(1)) if right_mat else None\n",
    "\n",
    "    if ls_len is not None:\n",
    "        print(f\"ls: 0-{ls_len}  \\n {wrap_str(predict.seq[:ls_len], txt_width)}\")\n",
    "        \n",
    "    if rs_len is not None:\n",
    "        print(f\"rs: {seq_len-rs_len}-{seq_len} \\n {wrap_str(predict.seq[-rs_len:], txt_width)}\")\n",
    "    \n",
    "    if predict_read.has_tag(\"SA\"):\n",
    "        print(f\"has sa\")\n",
    "        chimeric_alns = predict_read.get_tag(\"SA\")[:-1].split(\";\")\n",
    "\n",
    "        for _aln in chimeric_alns:\n",
    "            (\n",
    "                chr_sa,\n",
    "                pos_sa,\n",
    "                strand_sa,\n",
    "                cigar_sa,\n",
    "                mapq_sa,\n",
    "                nm_sa,\n",
    "            ) = _aln.split(\",\")\n",
    "    \n",
    "            left_mat = pat_left_s.search(cigar_sa)\n",
    "            right_mat = pat_right_s.search(cigar_sa)\n",
    "    \n",
    "            l_s_len = left_mat.group(1) if left_mat else \"\"\n",
    "            r_s_len = right_mat.group(1) if right_mat else \"\"\n",
    "    \n",
    "            tgt_key = f\"{predict_read.qname}\\t{l_s_len=}\\t{r_s_len=}\"\n",
    "            \n",
    "            print(f\"chimeric : {tgt_key}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in internal_chop_predicts[:50]:\n",
    "    show_sam_record(p, smooth_intervals, sam_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in more_than_one_smooth_preditions:\n",
    "    show_sam_record(p, smooth_intervals, sam_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in all_predicts_with_chop:\n",
    "    show_sam_record(p, smooth_intervals, sam_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "read.get_tag(\"SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for p in all_predicts_with_chop[200:]:\n",
    "    if idx > 10:\n",
    "        break\n",
    "    smooth_region = smooth_intervals[p.id]\n",
    "    if len(smooth_region) == 1:\n",
    "        idx +=1\n",
    "        print(p.id)\n",
    "        highlight_targets(p.seq, smooth_region)\n",
    "        p.vis_qual_static(smooth_region[0][0] -10 , smooth_region[0][1] +10  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_label_region(true_predcition[0], 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_label_region(true_predcition[0], 1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc",
   "language": "python",
   "name": "dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
