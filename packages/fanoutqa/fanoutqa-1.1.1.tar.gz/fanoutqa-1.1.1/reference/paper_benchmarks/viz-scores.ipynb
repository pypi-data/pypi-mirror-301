{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the data\n",
    "import json\n",
    "\n",
    "from bench.utils import REPO_ROOT\n",
    "\n",
    "settings = [\"closedbook\", \"openbook\", \"wiki-provided\"]\n",
    "setting_names = [\"Closed Book\", \"Open Book\", \"Evidence Provided\"]\n",
    "models = [\"llama-chat\", \"gpt-4\", \"gpt-3.5-turbo\", \"mistral-chat\", \"mixtral\", \"gpt-4-turbo\", \"claude\"]\n",
    "model_names = [\"LLaMA 2\", \"GPT-4\", \"GPT-3.5-turbo\", \"Mistral-7B\", \"Mixtral-8x7B\", \"GPT-4-turbo\", \"Claude 2.1\"]\n",
    "\n",
    "results_loose = {k: [] for k in setting_names}\n",
    "results_model = {k: [] for k in setting_names}\n",
    "\n",
    "# def print_one(fp):\n",
    "#     with open(fp) as f:\n",
    "#         scores = json.load(f)\n",
    "#     acc = scores[\"acc\"][\"acc\"]\n",
    "#     perf = scores[\"acc\"][\"perfect\"]\n",
    "#     r1p = scores[\"rouge\"][\"rouge1\"][\"precision\"]\n",
    "#     r1r = scores[\"rouge\"][\"rouge1\"][\"recall\"]\n",
    "#     r1f = scores[\"rouge\"][\"rouge1\"][\"fscore\"]\n",
    "#     r2p = scores[\"rouge\"][\"rouge2\"][\"precision\"]\n",
    "#     r2r = scores[\"rouge\"][\"rouge2\"][\"recall\"]\n",
    "#     r2f = scores[\"rouge\"][\"rouge2\"][\"fscore\"]\n",
    "#     rLp = scores[\"rouge\"][\"rougeL\"][\"precision\"]\n",
    "#     rLr = scores[\"rouge\"][\"rougeL\"][\"recall\"]\n",
    "#     rLf = scores[\"rouge\"][\"rougeL\"][\"fscore\"]\n",
    "#     bleurt = scores[\"bleurt\"]\n",
    "#     gptscore = scores[\"gpt\"]\n",
    "#     print(\",\".join(map(str, (acc, perf, r1p, r1r, r1f, r2p, r2r, r2f, rLp, rLr, rLf, bleurt, gptscore))))\n",
    "\n",
    "\n",
    "for setting, setting_name in zip(settings, setting_names):\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        result_path = REPO_ROOT / f\"results/score-{setting}-{model}.json\"\n",
    "        with open(result_path) as f:\n",
    "            scores = json.load(f)\n",
    "        loose = scores[\"acc\"][\"acc\"]\n",
    "        results_loose[setting_name].append(loose)\n",
    "        results_model[setting_name].append(scores[\"gpt\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53c8b7b5d53696f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc8afd1110f9c495"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# liam code\n",
    "def show_values(axs, orient=\"v\", space=.01, label_thresh=0):\n",
    "    def _single(ax):\n",
    "        if orient == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n",
    "                value = '{:.1f}'.format(p.get_height()*100)\n",
    "                if p.get_height() >= label_thresh:\n",
    "                    ax.text(_x, _y, value, ha=\"center\", fontsize=11) #, rotation=40)\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _single(ax)\n",
    "    else:\n",
    "        _single(axs)\n",
    "\n",
    "# # Put the intended figsize here\n",
    "# fig, ax = plt.subplots(figsize=(5,2.8))\n",
    "# \n",
    "# # Put your dataframe here \n",
    "# sns.barplot(ax=ax, data=df, y='accuracy', x='model', hue='chat')\n",
    "# \n",
    "# # Can customize legend here\n",
    "# ax.legend(loc='upper right', ncol=2, fontsize=12, columnspacing=0.5, labelspacing=0.3, handlelength=1.5, handletextpad=0.4, fancybox=False)\n",
    "\n",
    "\n",
    "# # Set size of text and other things\n",
    "# ax.xaxis.set_tick_params(labelsize=14)\n",
    "# \n",
    "# # Set no printing of axis label and set y limits\n",
    "# ax.set(xlabel=None)\n",
    "# ax.set(ylim=(0.0, 0.6))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78b8da145cbb5620",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "colors = mpl.colormaps[\"Set2\"].colors\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(11, 3.8))\n",
    "\n",
    "ax = axs[0]\n",
    "for idx, (attribute, measurement) in enumerate(results_loose.items()):\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute, color=colors[idx])\n",
    "    # ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Loose Accuracy', fontsize=12)\n",
    "# ax.set_title('Accuracy by Model and Task')\n",
    "ax.set_xticks(x + width, model_names, fontsize=12)\n",
    "\n",
    "# human perfomance\n",
    "ax.axhline(y=0.6853, label=\"Human (Open Book)\", color=colors[1], linestyle=\"--\")\n",
    "ax.set_ylim(0.1, 0.8)\n",
    "\n",
    "# ax.legend(loc='center right', bbox_to_anchor=(1.27, 0.6), fontsize=11)\n",
    "ax.legend(loc='upper left', ncols=4, fontsize=11)\n",
    "\n",
    "# Call cursed function\n",
    "show_values(ax, label_thresh=0.1)\n",
    "\n",
    "# ===== do it again =====\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "ax = axs[1]\n",
    "for idx, (attribute, measurement) in enumerate(results_model.items()):\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute, color=colors[idx])\n",
    "    # ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Model Judge Accuracy', fontsize=12)\n",
    "ax.set_xticks(x + width, model_names, fontsize=12)\n",
    "ax.set_ylim(0, 0.55)\n",
    "\n",
    "# human perfomance\n",
    "ax.axhline(y=0.4519, label=\"Human (Open Book)\", color=colors[1], linestyle=\"--\")\n",
    "\n",
    "# Call cursed function\n",
    "show_values(ax, label_thresh=0.015)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.15)\n",
    "\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"viz.pdf\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c68dbc694aed2aca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc24fd609a4b7ec8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
