[
  {
    "acc": {
      "loose": 0.3152160636708284,
      "strict": 0.05662983425414365
    },
    "rouge": {
      "rouge1": {
        "precision": 0.17356455306164578,
        "recall": 0.39150580236680255,
        "fscore": 0.20783575754357375
      },
      "rouge2": {
        "precision": 0.09085032002525105,
        "recall": 0.17549598793784338,
        "fscore": 0.10625950758793883
      },
      "rougeL": {
        "precision": 0.1532112048714597,
        "recall": 0.34618346407417766,
        "fscore": 0.18344705502411385
      }
    },
    "bleurt": 0.4267584370109587,
    "gpt": 0.1643646408839779,
    "name": "GPT-4",
    "authors": "OpenAI",
    "url": "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo",
    "citation": "OpenAI, 2023",
    "type": "FOUNDATION",
    "context": 8192
  },
  {
    "acc": {
      "loose": 0.4703468836864732,
      "strict": 0.10911602209944751
    },
    "rouge": {
      "rouge1": {
        "precision": 0.32591691806739764,
        "recall": 0.5274025346455309,
        "fscore": 0.35589614186761614
      },
      "rouge2": {
        "precision": 0.18949097802681353,
        "recall": 0.28817587063251693,
        "fscore": 0.20743984742825158
      },
      "rougeL": {
        "precision": 0.28537777495423555,
        "recall": 0.46967882341300493,
        "fscore": 0.31379331104952
      }
    },
    "bleurt": 0.4865400605212424,
    "gpt": 0.26243093922651933,
    "name": "GPT-4-turbo",
    "authors": "OpenAI",
    "url": "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo",
    "citation": "OpenAI, 2023",
    "type": "FOUNDATION",
    "context": 128000
  },
  {
    "acc": {
      "loose": 0.15469947220693514,
      "strict": 0.031767955801104975
    },
    "rouge": {
      "rouge1": {
        "precision": 0.09699008021536212,
        "recall": 0.19469418167728442,
        "fscore": 0.11418755334242695
      },
      "rouge2": {
        "precision": 0.040413694872158276,
        "recall": 0.08488911320642317,
        "fscore": 0.05075429578237907
      },
      "rougeL": {
        "precision": 0.0835343704701655,
        "recall": 0.1699066826399081,
        "fscore": 0.09861238283404707
      }
    },
    "bleurt": 0.33750931579022775,
    "gpt": 0.07596685082872928,
    "name": "GPT-3.5-turbo",
    "authors": "OpenAI",
    "url": "https://platform.openai.com/docs/models/gpt-3-5-turbo",
    "citation": "OpenAI, 2023",
    "type": "FOUNDATION",
    "context": 16384
  },
  {
    "acc": {
      "loose": 0.38953698927856806,
      "strict": 0.06353591160220995
    },
    "rouge": {
      "rouge1": {
        "precision": 0.09966641622516868,
        "recall": 0.47799987641310493,
        "fscore": 0.15662035695680138
      },
      "rouge2": {
        "precision": 0.04823947632622272,
        "recall": 0.21575914217888367,
        "fscore": 0.07543987012466698
      },
      "rougeL": {
        "precision": 0.08324811278648249,
        "recall": 0.40852712042925454,
        "fscore": 0.13141945954530423
      }
    },
    "bleurt": 0.4429991969951938,
    "gpt": 0.10773480662983426,
    "name": "LLaMA 2 70B",
    "authors": "Meta",
    "url": "https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/",
    "citation": "Touvron et al., 2023",
    "type": "FOUNDATION",
    "context": 4096
  },
  {
    "acc": {
      "loose": 0.024145046175432918,
      "strict": 0.0013812154696132596
    },
    "rouge": {
      "rouge1": {
        "precision": 0.007230514490414043,
        "recall": 0.029838755315060313,
        "fscore": 0.010116056959318522
      },
      "rouge2": {
        "precision": 0.0030492661970760036,
        "recall": 0.01235636714726415,
        "fscore": 0.004309447012284605
      },
      "rougeL": {
        "precision": 0.006576325561071797,
        "recall": 0.02700577469421076,
        "fscore": 0.009108932193761509
      }
    },
    "bleurt": 0.1700935731461858,
    "gpt": 0.011049723756906077,
    "name": "Mistral-7B",
    "authors": "Mistral AI",
    "url": "https://mistral.ai/news/announcing-mistral-7b/",
    "citation": "Jiang et al., 2023",
    "type": "FOUNDATION",
    "context": 32000
  },
  {
    "acc": {
      "loose": 0.3961719668514913,
      "strict": 0.055248618784530384
    },
    "rouge": {
      "rouge1": {
        "precision": 0.11787584988437909,
        "recall": 0.47223446046975565,
        "fscore": 0.17315178004485718
      },
      "rouge2": {
        "precision": 0.053319584239651184,
        "recall": 0.20480681092188244,
        "fscore": 0.07820162065687233
      },
      "rougeL": {
        "precision": 0.10000718238197719,
        "recall": 0.4077342141256453,
        "fscore": 0.147182462986372
      }
    },
    "bleurt": 0.4493722631107213,
    "gpt": 0.1477900552486188,
    "name": "Mixtral-8x7B",
    "authors": "Mistral AI",
    "url": "https://mistral.ai/news/mixtral-of-experts/",
    "citation": "Jiang et al., 2024",
    "type": "FOUNDATION",
    "context": 32000
  },
  {
    "acc": {
      "loose": 0.47120748528585843,
      "strict": 0.0856353591160221
    },
    "rouge": {
      "rouge1": {
        "precision": 0.2330077534090562,
        "recall": 0.5457109366018758,
        "fscore": 0.29497641803677077
      },
      "rouge2": {
        "precision": 0.12616194413675985,
        "recall": 0.2804704207979029,
        "fscore": 0.15747334844988234
      },
      "rougeL": {
        "precision": 0.19843856217260156,
        "recall": 0.4759886498517577,
        "fscore": 0.2527928960282501
      }
    },
    "bleurt": 0.48486519522594484,
    "gpt": 0.21823204419889503,
    "name": "Claude 2.1",
    "authors": "Anthropic",
    "url": "https://www.anthropic.com/news/claude-2-1",
    "citation": "Anthropic, 2023",
    "type": "FOUNDATION",
    "context": 200000
  }
]
