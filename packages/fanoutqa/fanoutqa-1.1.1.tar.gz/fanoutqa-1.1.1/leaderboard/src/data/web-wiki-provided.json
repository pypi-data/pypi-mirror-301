[
  {
    "acc": { "loose": 0.5456098545791228, "strict": 0.143646408839779 },
    "rouge": {
      "rouge1": {
        "precision": 0.4725312298278398,
        "recall": 0.6085356260042157,
        "fscore": 0.49998452049151393
      },
      "rouge2": {
        "precision": 0.2815675162719931,
        "recall": 0.35623992580949976,
        "fscore": 0.3005037957568856
      },
      "rougeL": {
        "precision": 0.38835972782295014,
        "recall": 0.5045559933909823,
        "fscore": 0.41272370572817085
      }
    },
    "bleurt": 0.5298143146528723,
    "gpt": 0.30386740331491713,
    "name": "GPT-4",
    "authors": "OpenAI",
    "url": "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo",
    "citation": "OpenAI, 2023",
    "type": "FOUNDATION",
    "context": 8192
  },
  {
    "acc": { "loose": 0.6281475667110468, "strict": 0.1919889502762431 },
    "rouge": {
      "rouge1": {
        "precision": 0.6321127734126731,
        "recall": 0.6764341478682872,
        "fscore": 0.6144612886380147
      },
      "rouge2": {
        "precision": 0.3984152059157445,
        "recall": 0.4292697483707228,
        "fscore": 0.39470073987610177
      },
      "rougeL": {
        "precision": 0.536314082392947,
        "recall": 0.5794550216005496,
        "fscore": 0.5226280415927149
      }
    },
    "bleurt": 0.5809288421923614,
    "gpt": 0.4129834254143646,
    "name": "GPT-4-turbo",
    "authors": "OpenAI",
    "url": "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo",
    "citation": "OpenAI, 2023",
    "type": "FOUNDATION",
    "context": 128000
  },
  {
    "acc": { "loose": 0.5165072478945334, "strict": 0.10220994475138122 },
    "rouge": {
      "rouge1": {
        "precision": 0.463516335636312,
        "recall": 0.5689152894435296,
        "fscore": 0.45546862566608826
      },
      "rouge2": {
        "precision": 0.24946325633429448,
        "recall": 0.31371309343477694,
        "fscore": 0.25221468710915207
      },
      "rougeL": {
        "precision": 0.3653434458264324,
        "recall": 0.45283802498465286,
        "fscore": 0.3581738799002991
      }
    },
    "bleurt": 0.49659434195546154,
    "gpt": 0.2430939226519337,
    "name": "GPT-3.5-turbo",
    "authors": "OpenAI",
    "url": "https://platform.openai.com/docs/models/gpt-3-5-turbo",
    "citation": "OpenAI, 2023",
    "type": "FOUNDATION",
    "context": 16384
  },
  {
    "acc": { "loose": 0.5143679183027113, "strict": 0.07734806629834254 },
    "rouge": {
      "rouge1": {
        "precision": 0.3407245588154435,
        "recall": 0.5902473705256917,
        "fscore": 0.3762628122180759
      },
      "rouge2": {
        "precision": 0.1832699274716267,
        "recall": 0.31368060953904164,
        "fscore": 0.20593914103223815
      },
      "rougeL": {
        "precision": 0.27518702361418795,
        "recall": 0.4795536695039635,
        "fscore": 0.30410024296144206
      }
    },
    "bleurt": 0.47221096980678773,
    "gpt": 0.16160220994475138,
    "name": "LLaMA 2 70B",
    "authors": "Meta",
    "url": "https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/",
    "citation": "Touvron et al., 2023",
    "type": "FOUNDATION",
    "context": 4096
  },
  {
    "acc": { "loose": 0.539846654625103, "strict": 0.08839779005524862 },
    "rouge": {
      "rouge1": {
        "precision": 0.25362992874397977,
        "recall": 0.6206499844406299,
        "fscore": 0.3300987746835614
      },
      "rouge2": {
        "precision": 0.13136173541137755,
        "recall": 0.31550366270027114,
        "fscore": 0.17182351464162274
      },
      "rougeL": {
        "precision": 0.20309078966310257,
        "recall": 0.5001600255631405,
        "fscore": 0.2639495371227864
      }
    },
    "bleurt": 0.4745529419974069,
    "gpt": 0.20165745856353592,
    "name": "Mistral-7B",
    "authors": "Mistral AI",
    "url": "https://mistral.ai/news/announcing-mistral-7b/",
    "citation": "Jiang et al., 2023",
    "type": "FOUNDATION",
    "context": 32000
  },
  {
    "acc": { "loose": 0.5760681994469418, "strict": 0.13535911602209943 },
    "rouge": {
      "rouge1": {
        "precision": 0.337280859260002,
        "recall": 0.6511326541771959,
        "fscore": 0.40933745120007703
      },
      "rouge2": {
        "precision": 0.1943735281050035,
        "recall": 0.3485360713472991,
        "fscore": 0.23141031987255675
      },
      "rougeL": {
        "precision": 0.282396718505277,
        "recall": 0.5503517413117182,
        "fscore": 0.34298526601178303
      }
    },
    "bleurt": 0.508856576296259,
    "gpt": 0.28314917127071826,
    "name": "Mixtral-8x7B",
    "authors": "Mistral AI",
    "url": "https://mistral.ai/news/mixtral-of-experts/",
    "citation": "Jiang et al., 2024",
    "type": "FOUNDATION",
    "context": 32000
  },
  {
    "acc": { "loose": 0.6531674930336602, "strict": 0.2154696132596685 },
    "rouge": {
      "rouge1": {
        "precision": 0.32045520128134836,
        "recall": 0.7180304376195379,
        "fscore": 0.42300161074719367
      },
      "rouge2": {
        "precision": 0.1979935998869878,
        "recall": 0.4389654131557785,
        "fscore": 0.26233077626475276
      },
      "rougeL": {
        "precision": 0.2663865768311303,
        "recall": 0.6115257311712957,
        "fscore": 0.3538037743008641
      }
    },
    "bleurt": 0.5081962022251187,
    "gpt": 0.4696132596685083,
    "name": "Claude 2.1",
    "authors": "Anthropic",
    "url": "https://www.anthropic.com/news/claude-2-1",
    "citation": "Anthropic, 2023",
    "type": "FOUNDATION",
    "context": 200000
  }
]
