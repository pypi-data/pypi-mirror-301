Metadata-Version: 2.1
Name: doclayout_yolo
Version: 0.0.1
Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.
Author: Glenn Jocher, Ayush Chaurasia, Jing Qiu
Maintainer: Glenn Jocher, Ayush Chaurasia, Jing Qiu
License: AGPL-3.0
Project-URL: Bug Reports, https://github.com/ultralytics/ultralytics/issues
Project-URL: Funding, https://ultralytics.com
Project-URL: Source, https://github.com/ultralytics/ultralytics/
Keywords: machine-learning,deep-learning,computer-vision,ML,DL,AI,YOLO,YOLOv3,YOLOv5,YOLOv8,HUB,Ultralytics
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Operating System :: POSIX :: Linux
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft :: Windows
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: matplotlib>=3.3.0
Requires-Dist: opencv-python>=4.6.0
Requires-Dist: pillow>=7.1.2
Requires-Dist: pyyaml>=5.3.1
Requires-Dist: requests>=2.23.0
Requires-Dist: scipy>=1.4.1
Requires-Dist: torch>=1.8.0
Requires-Dist: torchvision>=0.9.0
Requires-Dist: tqdm>=4.64.0
Requires-Dist: psutil
Requires-Dist: py-cpuinfo
Requires-Dist: thop>=0.1.1
Requires-Dist: pandas>=1.1.4
Requires-Dist: seaborn>=0.11.0
Provides-Extra: dev
Requires-Dist: ipython; extra == "dev"
Requires-Dist: check-manifest; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: coverage[toml]; extra == "dev"
Requires-Dist: mkdocs-material>=9.5.9; extra == "dev"
Requires-Dist: mkdocstrings[python]; extra == "dev"
Requires-Dist: mkdocs-jupyter; extra == "dev"
Requires-Dist: mkdocs-redirects; extra == "dev"
Requires-Dist: mkdocs-ultralytics-plugin>=0.0.44; extra == "dev"
Provides-Extra: explorer
Requires-Dist: lancedb; extra == "explorer"
Requires-Dist: duckdb<=0.9.2; extra == "explorer"
Requires-Dist: streamlit; extra == "explorer"
Provides-Extra: export
Requires-Dist: onnx>=1.12.0; extra == "export"
Requires-Dist: openvino>=2024.0.0; extra == "export"
Requires-Dist: coremltools>=7.0; (platform_system != "Windows" and python_version <= "3.11") and extra == "export"
Requires-Dist: tensorflow<=2.13.1; python_version <= "3.11" and extra == "export"
Requires-Dist: tensorflowjs>=3.9.0; python_version <= "3.11" and extra == "export"
Provides-Extra: extra
Requires-Dist: hub-sdk>=0.0.5; extra == "extra"
Requires-Dist: ipython; extra == "extra"
Requires-Dist: albumentations>=1.0.3; extra == "extra"
Requires-Dist: pycocotools>=2.0.7; extra == "extra"
Provides-Extra: logging
Requires-Dist: comet; extra == "logging"
Requires-Dist: tensorboard>=2.13.0; extra == "logging"
Requires-Dist: dvclive>=2.12.0; extra == "logging"

# [DocLayout-YOLO: Advancing Document Layout Analysis with Mesh-candidate Bestfit and Global-to-local perception](https://arxiv.org/abs/2405.14458)


Official PyTorch implementation of **DocLayout-YOLO**.

[DocLayout-YOLO: Advancing Document Layout Analysis with Mesh-candidate Bestfit and Global-to-local perception](https://arxiv.org/abs/2405.14458).\
Zhiyuan Zhao, Hengrui Kang, Bin Wang, Conghui He\
[![arXiv](https://img.shields.io/badge/arXiv-2405.14458-b31b1b.svg)](https://arxiv.org/abs/2405.14458)[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/kadirnar/Yolov10)

<details>
  <summary>
  <font size="+1">Abstract</font>
  </summary>
Document Layout Analysis (DLA) plays a critical role in real-world document understanding systems, yet it confronts a challenging speed-accuracy dilemma: multimodal methods leveraging text and visual features provide higher accuracy but suffer from glacial speed, whereas unimodal methods relying solely on visual features offer faster speed but at the cost of compromised accuracy. In addressing this dilemma, we introduce DocLayout-YOLO, which not only enhances accuracy but also preserves the speed advantage through optimization from pre-training and model perspectives in a document-tailored manner. In terms of robust document pretraining, we innovatively regard document synthetic as a 2D bin packing problem and introduce Mesh-candidate Bestfit, which enables the generation of large-scale, diverse document datasets. The model, pre-trained on the resulting DocSynth300K dataset, significantly enhances fine-tuning performance across a variety of document types. In terms of model enhancement for document understanding, we propose a Global-to-local Controllable Receptive Module which emulates the human visual process from global to local perspectives and features a controllable module for feature extraction and integration. Furthermore, to validate performance across different document types, we propose a complex and challenging benchmark named DocStructBench. Experimental results on extensive downstream datasets show that the proposed DocLayout-YOLO excels at both speed and accuracy. Code, data, and model will be made publicly available.
</details>


## Installation
`conda` virtual environment is recommended. 
```
conda create -n doclayout_yolo python=3.9
conda activate doclayout_yolo
pip install -r requirements.txt
pip install -e .
```

## Data Preparation

1. specify data root path

Find your ultralytics config file (for Linux user in $HOME/.config/Ultralytics/settings.yaml) and change ```datasets_dir``` to project root path.

2. Download prepared yolo-format D4LA and doclaynet data from below and put to ./layout_data, the file structure is as follows:

```bash
./layout_data
├── D4LA
│   ├── images
│   ├── labels
│   ├── test.txt
│   └── train.txt
└── doclaynet
    ├── images
    ├── labels
    ├── val.txt
    └── train.txt
```


## Acknowledgement

The code base is built with [ultralytics](https://github.com/ultralytics/ultralytics) and [YOLO-v10](https://github.com/lyuwenyu/RT-DETR).

Thanks for the great implementations! 

## Citation

If our code or models help your work, please cite our paper:
```BibTeX
@misc{wang2024yolov10,
      title={YOLOv10: Real-Time End-to-End Object Detection}, 
      author={Ao Wang and Hui Chen and Lihao Liu and Kai Chen and Zijia Lin and Jungong Han and Guiguang Ding},
      year={2024},
      eprint={2405.14458},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
